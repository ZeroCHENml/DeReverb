\small{In real world environments, speech is heard as a mix of direct signal with reflections caused by the surrounding environment. Late reflections decrease speech intelligibility, causing problems for listeners, as well as tasks such as \ac{ASR} \todo[inline]{cite}. Using multiple microphones, reverberation can be removed by exploiting the spatial differences between direct and reverberant sound, however this requires increased hardware cost. An algorithm is then required which can remove the effects of reverberation using only a single channel of audio. Traditional signal processing approaches can solve this problem, however these algorithms typically do not leverage the structure of speech, as this is difficult to model mathematically. Neural networks have the capability to learn the structure of speech from data, potentially allowing for superior performance to traditional algorithms.}
