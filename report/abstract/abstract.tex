This work compares the performance of time and frequency domain approaches to speech dereverberation using u-net architectures. Towards this end, a neural architecture is constructed consisting of a u-net with a recurrent latent layer. Two models of this architecture are trained, one using time-domain samples as inputs, one using frequency domain magnitudes as inputs. Results are compared using the \ac{STOI} and \ac{PESQ} metrics. Additionally, a simple frequency-domain perceptually weighted loss function is presented.
